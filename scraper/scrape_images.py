"""
Sonny Angel Image Scraper

Downloads angel images from the official Sonny Angel website
based on the gallery_config.json generated by discover_galleries.py.
"""

import os
import requests
from bs4 import BeautifulSoup
import json
import time
import re


def download_series_images(series_url: str, series_name: str, section_id: str):
    """Download all images for a series from a gallery page."""
    save_directory = f"images/{series_name}_Series/"
    os.makedirs(save_directory, exist_ok=True)

    response = requests.get(series_url, timeout=30)
    soup = BeautifulSoup(response.text, "html.parser")

    series_section = soup.find("div", id=section_id)

    if not series_section:
        print(f"Could not find section with id {section_id} for {series_name}.")
        return 0

    gallery_items = series_section.find_all("a", class_="fg-thumb")
    downloaded_count = 0

    for item in gallery_items:
        image_url = item.get("href")
        caption_title = item.get("data-caption-title")

        if not image_url or not caption_title:
            continue

        safe_title = caption_title.replace(" ", "_").replace("/", "_")
        image_filename = f"{safe_title}.png"
        image_path = os.path.join(save_directory, image_filename)

        if os.path.exists(image_path):
            print(f"  Skipped (exists): {image_filename}")
            continue

        try:
            image_response = requests.get(image_url, timeout=30)
            image_response.raise_for_status()

            with open(image_path, "wb") as f:
                f.write(image_response.content)

            print(f"  Saved: {image_filename}")
            downloaded_count += 1
            time.sleep(0.5)

        except Exception as e:
            print(f"  Error downloading {caption_title}: {e}")

    return downloaded_count


def load_gallery_config(config_file: str = "gallery_config.json") -> dict:
    """Load gallery configuration from JSON file."""
    with open(config_file, "r") as f:
        return json.load(f)


def safe_series_folder_name(raw: str) -> str:
    """
    Convert website series titles into storage-safe folder names.

    Supabase Storage rejects some characters in object keys (e.g. '(', ')', '~').
    We normalize titles into ASCII-ish, underscore-separated names.

    Examples:
      "Animal Series 1 (~2018)" -> "Animal_Series_1_2018"
      "Fruit Series (~2019)" -> "Fruit_Series_2019"
    """
    s = raw.strip()
    s = re.sub(r"\(~\s*(\d{4})\s*\)", r"\1", s)
    s = re.sub(r"\s+", "_", s)
    s = re.sub(r"[^A-Za-z0-9_-]+", "_", s)
    s = re.sub(r"_+", "_", s).strip("_")
    return s


def scrape_from_config():
    """Main scraping function - processes all galleries from config."""
    print("Loading gallery configuration...")

    try:
        config = load_gallery_config()
    except FileNotFoundError:
        print("Error: gallery_config.json not found!")
        print("Please run: python discover_galleries.py")
        return

    print(f"Found {len(config)} product types\n")

    total_series = sum(len(galleries) for galleries in config.values())
    print(f"Total series to scrape: {total_series}\n")

    total_downloaded = 0

    for product_type, galleries in config.items():
        print(f"\n{'='*60}")
        print(f"Scraping: {product_type} ({len(galleries)} series)")
        print(f"{'='*60}\n")

        for gallery in galleries:
            series_name = safe_series_folder_name(gallery["series_name"])
            series_url = gallery["url"]
            gallery_id = gallery["gallery_id"]

            print(f"Processing: {gallery['series_name']}")
            downloaded = download_series_images(series_url, series_name, gallery_id)
            total_downloaded += downloaded
            print()

    print(f"\n{'='*60}")
    print(f"Scraping complete! Downloaded {total_downloaded} images.")
    print(f"{'='*60}")


if __name__ == "__main__":
    scrape_from_config()
